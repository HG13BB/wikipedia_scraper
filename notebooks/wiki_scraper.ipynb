{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_filetypes = 'https://en.wikipedia.org/wiki/List_of_file_formats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(wp_filetypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idenfity the heading tags\n",
    "#create dict to track starting line of each heading tag\n",
    "heading_tags = [\"h1\", \"h2\", \"h3\",\"h4\"]\n",
    "heading_pos = [i.sourceline for i in soup.find_all(heading_tags)]\n",
    "heading_text = [i.text for i in soup.find_all(heading_tags)]\n",
    "\n",
    "#identify the content that we are interested in and the related links\n",
    "#track the line positions of each\n",
    "\n",
    "#text and position of content\n",
    "content_pos = [i.sourceline for i in soup.find_all('li')]\n",
    "content_text = [i.text for i in soup.find_all('li')]\n",
    "\n",
    "#links\n",
    "href_pos = [i.sourceline for i in soup.find_all('a',href=True)]\n",
    "href_link = [i['href'] for i in soup.find_all('a',href=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_pos(poslist,contentlist):\n",
    "    #construct a dict to hold the starting and ending line of each element you are processing\n",
    "    #input: two lists of same length\n",
    "    #output: dict of tuples with start and end pos\n",
    "    poses = {}\n",
    "\n",
    "    for item in range(len(contentlist)):\n",
    "        begin = poslist[item]\n",
    "        \n",
    "        #create tuple with beginning and ending indexes of each heading\n",
    "        if item == len(poslist)-1:\n",
    "            end = content_pos[-1] #if end of heading list take last content tag pos\n",
    "        else:\n",
    "            end = poslist[item+1]-1  #next line minus 1\n",
    "        \n",
    "        poses[contentlist[item]] = (begin,end)\n",
    "\n",
    "    return poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading_scope = get_tag_pos(heading_pos,heading_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_scope = get_tag_pos(content_pos,content_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_scope = get_tag_pos(href_pos,href_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_links(content,links):\n",
    "    #create dict to connect the text from list content \n",
    "    #to relevant tags\n",
    "    #input: two dicts\n",
    "    #output: nested dict\n",
    "    content_links = {}\n",
    "\n",
    "    for text in content:\n",
    "        \n",
    "        #nest dict holds the position of the content and the link\n",
    "        temp = {}\n",
    "        temp['pos'] = content[text]\n",
    "        temp['link'] = []\n",
    "                    \n",
    "        for link in links:\n",
    "            if content[text][0] <= links[link][0] <= content[text][1]:\n",
    "                temp['link'].append(link)\n",
    "\n",
    "        content_links[text] = temp\n",
    "    \n",
    "    return content_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_links = connect_links(content_scope,links_scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_hdr_content(hdr,content):\n",
    "    #join the headers with the content (file types and links) based on position\n",
    "    \n",
    "    hdr_cont_out = dict(zip(hdr.keys(), ([] for _ in hdr.keys())))\n",
    "    #hdr_cont_out_lnk = dict(zip(hdr.keys(), ([] for _ in hdr.keys())))\n",
    "\n",
    "    for h in hdr:\n",
    "        for c in content:\n",
    "            #check if the file info tag is at the position of the heading\n",
    "            if hdr[h][0] <= content[c]['pos'][0] <= hdr[h][1]:\n",
    "                file_info = []\n",
    "                file_info.append(c)\n",
    "                \n",
    "                if len(content[c]['link']) > 0:\n",
    "                    file_info.append(content[c]['link'][0])\n",
    "                else:\n",
    "                    file_info.append(None)\n",
    "\n",
    "                hdr_cont_out[h].append(file_info)\n",
    "\n",
    "    \n",
    "    #remove unneeded items in the final output\n",
    "    return  {k: v for k, v in hdr_cont_out.items() if k.endswith('[edit]')}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = join_hdr_content(heading_scope,files_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def df_from_wpdict(wpdict):\n",
    "    #create a dataframe for each item in a dict and append to a main df\n",
    "    #dict -> df\n",
    "    \n",
    "    df_cols = ['file_category','file_info','wikilink']\n",
    "    filetypes = pd.DataFrame(columns=df_cols)\n",
    "    \n",
    "    \n",
    "    #loop through the dict items and append to the df\n",
    "    for k in wpdict:\n",
    "        for f in wpdict[k]:\n",
    "            data = [k,f[0],f[1]]\n",
    "            df = pd.DataFrame([data],columns=df_cols)\n",
    "            filetypes = filetypes.append(df)\n",
    "    \n",
    "    return filetypes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft = df_from_wpdict(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fc(value):\n",
    "    #clean the text in file_category\n",
    "    return value.replace('[edit]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_elrf(df):\n",
    "    #remove the headings that related to external links and references\n",
    "    #in the wikipedia article\n",
    "    return df[~df.file_category.isin(['External links','References','See also'])].reset_index().drop('index',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft.file_category = df_ft.file_category.apply(clean_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft_rm = remove_elrf(df_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_links(value):\n",
    "    #clean up the wikipedia links to just include this from wikipedia\n",
    "    if value:\n",
    "        if '/wiki/' in value:\n",
    "            return 'https://en.wikipedia.org/' + value\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft_rm.wikilink = df_ft_rm.wikilink.apply(clean_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file_ext(value):\n",
    "    #extract a file extension from string\n",
    "    if value:\n",
    "        if '-' in value:\n",
    "            return value.split('-')[0]\n",
    "        if ' – ' in value:\n",
    "            return value.split(' – ')[0]\n",
    "        else:\n",
    "            pass \n",
    "        \n",
    "        \n",
    "        #else:\n",
    "        #    re.findall(r'\\.\\w+',value)[0].replace('.','')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_filetypes(value):\n",
    "    #function leverages re to pull \n",
    "    \n",
    "    result_dot = re.findall(r'\\.\\w+',value)\n",
    "    result_dot = [i.replace('.','') for i in result_dot]\n",
    "\n",
    "\n",
    "    result_nodot = re.findall(r'\\w{3,}',value)\n",
    "    \n",
    "    if len(result_dot) > 0:\n",
    "        return result_dot\n",
    "\n",
    "    elif len(result_nodot) > 0:\n",
    "        return result_nodot[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_re_ft(df):\n",
    "    #apply the re filetypes and create new rows for each file extension\n",
    "    #for one row of df\n",
    "    filter_values = list(df.file_info)\n",
    "\n",
    "    final_df = df.copy().truncate(after=0)\n",
    "\n",
    "    for fi in filter_values:\n",
    "        indf = df[df.file_info == fi]\n",
    "\n",
    "        outdf = indf.copy()\n",
    "\n",
    "        value = list(outdf.file_info)[0]\n",
    "        \n",
    "        ft_values =  re_filetypes(value)\n",
    "\n",
    "        if  len(ft_values) > 1:\n",
    "            \n",
    "            for item in ft_values:\n",
    "                tempdf = outdf.copy()\n",
    "                tempdf.file_ext = item\n",
    "                outdf = outdf.append(tempdf)\n",
    "\n",
    "            outdf =  outdf[outdf.file_ext.isna() == False]\n",
    "\n",
    "        else:\n",
    "            outdf.file_ext = ft_values[0]\n",
    "\n",
    "        final_df = final_df.append(outdf)\n",
    "\n",
    "    return final_df[final_df.file_ext.str.len() > 1].drop_duplicates()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft_rm_nulls = apply_re_ft(df_ft_rm[df_ft_rm.file_ext.isna()==True])\n",
    "df_ft_rm_nonnulls = df_ft_rm[~df_ft_rm.file_ext.isna()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_ft_rm_nonnulls.append(df_ft_rm_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_output():\n",
    "    return df_out"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4bd76f36fa07c92d423ad5d1d2cbe0ac2e2f53edb5b0446e053ad16aa699156"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
